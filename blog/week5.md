# Bias in Machine Learning

Since I have researched about the ethical issues of technology in college as a philosophy majored student, the concept of bias in reference of machine learning has been a main concern for years.

There are many recent observations show that AI is just as capable of bias as humans, even though they run on mathematics. The reason why AI tools are not free from bias because they learn from their human makers and their biases. At this point, it seems like just an extension of human nature and culture.

Quotes by Nicole Shadowen in her blog "[Machine bias](https://www.technologyreview.com/s/608248/biased-algorithms-are-everywhere-and-no-one-seems-to-care/) is the growing body of research around the ways in which algorithms exhibit the bias of their creators or their input data. As machine learning is increasingly used across all industries, bias is being discovered with subtle and obvious consequences. It is important to note that machine learning algorithms rely on bias — statistical bias. These algorithms could not make any predictions at all if it wasn’t for the statistical bias required to make estimations about new data that the model has never seen before. Machine bias is different than statistical bias. Said simply — machine bias is programming that assumes the prejudice of its creators or data."

A several studies by universities and researchers found that machines showd biases similar to those found in the humans. For instance, the word “men” was associated with words like “work,” “math,” and “science” while the word “women” was associated with “family” and “the arts.” And young people, flowers, and musical instruments were considered more pleasant than old people, insects (Gil Grissom from “CSI” is the person who loves insects and enjoys racing cockroaches, which is not an appealing hobby) or weapons. As mentioned in the last class, this has been an issue for some time, as evidence of AI bias was found in recruiting, online advertising, and pricing. What’s surprising is that all of these are driven by so-called neutral algorithms. It is concerning because it could result in several problems. Not even Google is free from bias. When using Google Translate, the tool automatically converted gender-neutral pronouns into male or female. For instance, “doctor” was converted to “he” and nurse to “she.”
We can find these problems from other ML fields such as face recognition. Some instances:
Google Photos auto-tagging African-Americans as apes in some images.
Microsoft Kinect having a tough time in recognizing people with dark skin tone.
Passport systems reading Asians’ images as people with their eyes closed and rejecting the uploaded images.

Furthermore, it’s not only limited or skewed data that could create deep-rooted biases in machine learning algorithms driving AI applications. The biases could result not only from the data feeded, but also from interactions with real users. Here are some examples from another article:

Microsoft’s Tay, a Twitter-based chatbot, was absolutely ruined as a result of its interactions with a user community that proved to be highly racist and misogynistic. The result — that chatbot started posting aggressive, racist, and misogynist tweets, causing Microsoft to promptly pull it down, after a mere 24 hours of going live. That chatbot could not think for itself, obviously — it needed to be given some commonsense and tact in its algorithm.

Emergent bias is another source, and though it’s one of the lesser known, it’s the scariest of them all. Consider Facebook: You like a certain kind of statuses, posts, and videos, and you can expect your timeline to be loaded with content “more like the same” as you liked earlier.

This is called “confirmation bias,” wherein the beliefs and values of an individual, related to anything (as trivial as one’s favorite TV series genre to as far-reaching as one’s political affiliations), get reinforced one day after another, purely because the individual is hardly exposed to contradictory information. When Elon Musk calls AI “an existential threat,” it stems a lot from the potential of AI to absolutely numb down the human ability to mature, evolve, change, and adjust, because of emergent biases.

What is most concerning is that we might never be able to fathom how machines can also turn discriminatory, and keep being treated unfairly without realizing it. To solve the problem, the people creating the tools and entering data in them must be free from biases or at least know that they have them and make sure they aren’t imparted into the machines.
But ultimately, all data-driven tools created by humans will always have some amount of bias. However, by acknowledging the existence of these biases, identifying their sources, and eliminating them, AI can be made a lot more objective. It is up to all of us to determine the path machine learning algorithms take.
